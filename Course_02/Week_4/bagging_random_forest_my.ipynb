{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бэггинг и случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите датасет digits с помощью функции load_digits из sklearn.datasets и подготовьте матрицу признаков X и ответы на обучающей выборке y (вам потребуются поля data и target в объекте, который возвращает load_digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества далее нужно будет использовать cross_val_score из sklearn.cross_validation с параметром cv=10. Эта функция реализует k-fold cross validation c k равным значению параметра cv. Мы предлагаем использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и k=5. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет k чисел - качество в каждом из k экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает cross_val_score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С небольшой вероятностью вы можете натолкнуться на случай, когда полученное вами качество в каком-то из пунктов не попадет в диапазон, заданный для правильных ответов - в этом случае попробуйте перезапустить ячейку с cross_val_score несколько раз и выбрать наиболее «типичное» значение. Если это не помогает, то где-то была допущена ошибка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вам захочется ускорить вычисление cross_val_score - можете попробовать использовать параметр n_jobs, но будьте осторожны: в одной из старых версий sklearn была ошибка, которая приводила к неверному результату работы cross_val_score при задании n_jobs отличным от 1. Сейчас такой проблемы возникнуть не должно, но проверить, что все в порядке, не будет лишним."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте DecisionTreeClassifier с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score. Эта величина и будет ответом в пункте 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8359837582\n"
     ]
    }
   ],
   "source": [
    "# kvd: решение было взято отсюда:\n",
    "# https://github.com/sknsht/machine-learning-data-analysis/blob/master/supervised-learning/W4/HW/assignment_1/bagging_random_forest.ipynb\n",
    "#\n",
    "# В этом решении используется cross_val_score из модуля sklearn.model_selection.\n",
    "# В этом случае получается ответ 0.833156860639 (этот ответ был принят как правильный).\n",
    "#\n",
    "# Но для этого нужно использовать sklearn версии 0.18 и выше.\n",
    "#\n",
    "# У меня установлена версия sklearn 0.17.\n",
    "# Чтобы посмотреть версию, запускаем 2 строки:\n",
    "#    import sklearn\n",
    "#    sklearn.__version__\n",
    "#\n",
    "# У меня сработал вариант с функцией cross_val_score из sklearn.cross_validation.\n",
    "# Но при этом ответ получается другой 0.821952076178.\n",
    "#\n",
    "# Не удалосб обновить scikit-learn этой командой:\n",
    "#    pip install -U scikit-learn\n",
    "# Чтобы обновить scikit-learn, запускаем команду в омандной строке Windows (это тоже не получилось):\n",
    "#    easy_install --upgrade scikit-learn\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "# from sklearn.model_selection import cross_val_score # kvd comment\n",
    "from sklearn import cross_validation # kvd\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "#score = np.mean(cross_val_score(clf, X, y, cv=10)) # kvd comment\n",
    "score = np.mean(cross_validation.cross_val_score(clf, X, y, cv=10)) # kvd\n",
    "\n",
    "print score\n",
    "\n",
    "def write_answer_1(score):\n",
    "    with open(\"bagging_random_forest1.txt\", \"w\") as file_obj:\n",
    "        file_obj.write(str(score))\n",
    "\n",
    "write_answer_1(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуйтесь BaggingClassifier из sklearn.ensemble, чтобы обучить бэггинг над DecisionTreeClassifier. Используйте в BaggingClassifier параметры по умолчанию, задав только количество деревьев равным 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество классификации новой модели - ответ в пункте 2. Обратите внимание, как соотносится качество работы композиции решающих деревьев с качеством работы одного решающего дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.923231983665\n"
     ]
    }
   ],
   "source": [
    "# В этом решении используется cross_val_score из модуля sklearn.model_selection.\n",
    "# В этом случае получается ответ 0.928797952315 (этот ответ был принят как правильный).\n",
    "# \n",
    "# У меня сработал вариант с функцией cross_val_score из sklearn.cross_validation.\n",
    "# Но при этом ответ получается другой 0.923231983665.\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "        \n",
    "clf = BaggingClassifier(n_estimators=100)\n",
    "# score = np.mean(cross_val_score(clf, X, y, cv=10)) # kvd comment\n",
    "score = np.mean(cross_validation.cross_val_score(clf, X, y, cv=10)) # kvd\n",
    "print score\n",
    "\n",
    "def write_answer_2(score):\n",
    "    with open(\"bagging_random_forest2.txt\", \"w\") as file_obj:\n",
    "        file_obj.write(str(score))\n",
    "        \n",
    "write_answer_2(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех d признаках, а на $\\sqrt {d}$ случайных признаков. Качество работы получившегося классификатора - ответ в пункте 3. Корень из числа признаков - часто используемая эвристика в задачах классификации, в задачах регрессии же часто берут число признаков, деленное на три. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признако"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927685873391\n"
     ]
    }
   ],
   "source": [
    "# В этом решении используется cross_val_score из модуля sklearn.model_selection.\n",
    "# В этом случае получается ответ 0.930519480226 (этот ответ был принят как правильный).\n",
    "# \n",
    "# У меня сработал вариант с функцией cross_val_score из sklearn.cross_validation.\n",
    "# Но при этом ответ получается другой 0.927685873391.\n",
    "\n",
    "d = X.shape[1]\n",
    "num_features = int(np.sqrt(d))\n",
    "\n",
    "clf = BaggingClassifier(n_estimators=100, max_features=num_features)\n",
    "# score = np.mean(cross_val_score(clf, X, y, cv=10)) # kvd comment\n",
    "score = np.mean(cross_validation.cross_val_score(clf, X, y, cv=10)) # kvd\n",
    "print score\n",
    "\n",
    "def write_answer_3(score):\n",
    "    with open(\"bagging_random_forest3.txt\", \"w\") as file_obj:\n",
    "        file_obj.write(str(score))\n",
    "        \n",
    "\n",
    "write_answer_3(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, давайте попробуем выбирать случайные признаки не один раз на все дерево, а при построении каждой вершины дерева. Сделать это несложно: нужно убрать выбор случайного подмножества признаков в BaggingClassifier и добавить его в DecisionTreeClassifier. Какой параметр за это отвечает, можно понять из документации sklearn, либо просто попробовать угадать (скорее всего, у вас сразу получится). Попробуйте выбирать опять же $\\sqrt{d}$ признаков. Качество полученного классификатора на контрольной выборке и будет ответом в пункте 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948884593125\n"
     ]
    }
   ],
   "source": [
    "# В этом решении используется cross_val_score из модуля sklearn.model_selection.\n",
    "# В этом случае получается ответ 0.949968414719 (этот ответ был принят как правильный).\n",
    "# \n",
    "# У меня сработал вариант с функцией cross_val_score из sklearn.cross_validation.\n",
    "# Но при этом ответ получается другой 0.948884593125.\n",
    "\n",
    "clf = BaggingClassifier(DecisionTreeClassifier(max_features=num_features), n_estimators = 100)\n",
    "# score = np.mean(cross_val_score(clf, X, y, cv=10)) # kvd comment\n",
    "score = np.mean(cross_validation.cross_val_score(clf, X, y, cv=10)) # kvd\n",
    "print score\n",
    "\n",
    "def write_answer_4(score):\n",
    "    with open(\"bagging_random_forest4.txt\", \"w\") as file_obj:\n",
    "        file_obj.write(str(score))\n",
    "        \n",
    "\n",
    "write_answer_4(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный в пункте 4 классификатор - бэггинг на рандомизированных деревьях (в которых при построении каждой вершины выбирается случайное подмножество признаков и разбиение ищется только по ним). Это в точности соответствует алгоритму Random Forest, поэтому почему бы не сравнить качество работы классификатора с RandomForestClassifier из sklearn.ensemble. Сделайте это, а затем изучите, как качество классификации на данном датасете зависит от количества деревьев, количества признаков, выбираемых при построении каждой вершины дерева, а также ограничений на глубину дерева. Для наглядности лучше построить графики зависимости качества от значений параметров, но для сдачи задания это делать не обязательно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе наблюдений выпишите через пробел номера правильных утверждений из приведенных ниже в порядке возрастания номера (это будет ответ в п.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Случайный лес сильно переобучается с ростом количества деревьев\n",
    "\n",
    "2. При очень маленьком числе деревьев (5, 10, 15), случайный лес работает хуже, чем при большем числе деревьев\n",
    "\n",
    "3. С ростом количества деревьев в случайном лесе, в какой-то момент деревьев становится достаточно для высокого качества классификации, а затем качество существенно не меняется.\n",
    "\n",
    "4. При большом количестве признаков (для данного датасета - 40, 50) качество классификации становится хуже, чем при малом количестве признаков (5, 10). Это связано с тем, что чем меньше признаков выбирается в каждом узле, тем более различными получаются деревья (ведь деревья сильно неустойчивы к изменениям в обучающей выборке), и тем лучше работает их композиция.\n",
    "\n",
    "5. При большом количестве признаков (40, 50, 60) качество классификации лучше, чем при малом количестве признаков (5, 10). Это связано с тем, что чем больше признаков - тем больше информации об объектах, а значит алгоритм может делать прогнозы более точно.\n",
    "\n",
    "6. При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса намного лучше, чем без ограничения глубины, т.к. деревья получаются не переобученными. С ростом глубины деревьев качество ухудшается.\n",
    "\n",
    "7. При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса заметно хуже, чем без ограничений, т.к. деревья получаются недообученными. С ростом глубины качество сначала улучшается, а затем не меняется существенно, т.к. из-за усреднения прогнозов и различий деревьев их переобученность в бэггинге не сказывается на итоговом качестве (все деревья преобучены по-разному, и при усреднении они компенсируют переобученность друг-друга)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954480094669\n"
     ]
    }
   ],
   "source": [
    "# В этом решении используется cross_val_score из модуля sklearn.model_selection.\n",
    "# В этом случае получается ответ 0.952245570589 (этот ответ не отправлялся, \n",
    "#      потому что в п 5. нужно перечислить правильные пункты, а не отправить качество классификатора).\n",
    "# \n",
    "# У меня сработал вариант с функцией cross_val_score из sklearn.cross_validation.\n",
    "# Но при этом ответ получается другой 0.954480094669.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_features=num_features)\n",
    "# score = np.mean(cross_val_score(clf, X, y, cv=10)) # kvd comment\n",
    "score = np.mean(cross_validation.cross_val_score(clf, X, y, cv=10)) # kvd\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kvd: всё, что ниже, в задании не было."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Зависимость от количества деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = np.arange(5, 100, 5)\n",
    "scores = []\n",
    "for n in estimators:\n",
    "    clf = RandomForestClassifier(n_estimators=n, max_features=num_features)\n",
    "    scores.append(np.mean(cross_val_score(clf, X, y, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(estimators, scores)\n",
    "plt.xlabel('number of trees')\n",
    "plt.ylabel('score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Зависимость от количества признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.arange(5, d, 5)\n",
    "scores = []\n",
    "for n in features:\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_features=n)\n",
    "    scores.append(np.mean(cross_val_score(clf, X, y, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(features, scores)\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Зависимость от глубины деревьев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depths = np.arange(1, 30, 3)\n",
    "scores = []\n",
    "for n in depths:\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=n)\n",
    "    scores.append(np.mean(cross_val_score(clf, X, y, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(depths, scores)\n",
    "plt.xlabel('depth of trees')\n",
    "plt.ylabel('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers = [2, 3, 4, 7]\n",
    "\n",
    "def write_answer_5(answers):\n",
    "    with open(\"bagging_random_forest5.txt\", \"w\") as file_obj:\n",
    "        file_obj.write(\" \".join([str(num) for num in answers]))\n",
    "        \n",
    "write_answer_5(answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
